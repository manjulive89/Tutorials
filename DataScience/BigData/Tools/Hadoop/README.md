# Hadoop

* Gatering & Storing Data
* Processsing data
* Analysing Data

## Hadoop Distributed File System (HDFS)
Hadoop Distributed File System is a distributed file system with build-in redundancies that handles large data sets running on commodity hardware. AWS S3 is an example of HDFS.

All the modules in Hadoop are designed with a fundamental assumption that hardware failures are common occurrences and should be automatically handled by the framework.

It is used to scale a single Apache Hadoop cluster to hundreds (and even thousands) of nodes.

## Hadoop Componenets

The followings are the major components of Hadoop;

* HDFS is one of the major components of Apache Hadoop,
* MapReduce
* YARN

Apache HBase, which is a column-oriented non-relational database management system that sits on top of HDFS and can better support real-time data needs with its in-memory processing engine.
